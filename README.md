# Projet_DSIA_4201C : Statistiques des contenus Netflix dans le top 10  

## Description  

Le projet **Projet_DSIA_4201C** a pour objectif d'afficher des statistiques sur les films et sÃ©ries prÃ©sents dans le top 10 Netflix Ã  l'Ã©chelle mondiale et pour chaque pays.  

Ce projet repose sur un pipeline de **scraping**,du**stockage sur une BDD** et une **visualisation dynamique**, le tout organisÃ© en plusieurs conteneurs Docker.  

- **Scrapy** rÃ©cupÃ¨re les donnÃ©es sur le site Netflix Top 10.  
- **MongoDB** stocke les donnÃ©es du top 10 mondial.  
- **Elasticsearch** stocke les classements des 93 pays disponibles.  
- **Dash** permet de visualiser et d'interagir avec ces donnÃ©es via une interface web.  

L'ensemble des conteneurs est orchestrÃ© par **Docker Compose** pour simplifier le dÃ©ploiement ainsi que sa portabilitÃ©e.  

---

## Architecture du Projet  

Le projet est organisÃ© en **4 types de conteneurs** interconnectÃ©s :  

### 1ï¸âƒ£ **Scrapy (Python) : Extraction des donnÃ©es**  

Scrapy est utilisÃ© pour extraire les donnÃ©es depuis [https://www.netflix.com/tudum/top10](https://www.netflix.com/tudum/top10). Deux spiders ont Ã©tÃ© crÃ©Ã©es :  

- **`netflix_top10`** :  
  - Scrape le top 10 mondial des films et sÃ©ries.  
  - Stocke ces donnÃ©es dans **MongoDB** via une pipeline Scrapy.  

- **`netflix_top10_country`** :  
  - Scrape les classements pour chacun des **93 pays**.  
  - Stocke ces donnÃ©es dans **Elasticsearch** via une autre pipeline Scrapy.  

**Pipelines Scrapy :**  
Les pipelines permettent dâ€™envoyer automatiquement les donnÃ©es scrappÃ©es vers la base de donnÃ©es correspondante.  

- **MongoDBPipeline** : InsÃ¨re uniquement les **top 10 mondiaux** dans MongoDB.  
- **ElasticsearchPipeline** : Stocke les donnÃ©es des **93 pays** dans Elasticsearch.  

---

### 2ï¸âƒ£ **MongoDB : Stockage des donnÃ©es simplifiÃ©es**  

MongoDB est utilisÃ© pour stocker **uniquement** le top 10 **mondial** (films et sÃ©ries).  

- Contenu stockÃ© :  
  - `title` : Nom du film/sÃ©rie.  
  - `category` : Film ou sÃ©rie.  
  - `rank` : Position dans le top 10 mondial.  
  - `week` : Nombre de semaines dans le top 10.  

MongoDB est principalement utilisÃ© pour **gÃ©nÃ©rer des graphiques en barres** simples.  

---

### 3ï¸âƒ£ **Elasticsearch : Indexation et recherche**  

Elasticsearch stocke les **top 10 des 93 pays** sous forme d'index permettant une recherche rapide.  

- Contenu stockÃ© :  
  - `title` : Nom du film/sÃ©rie.  
  - `categorie` : Film ou sÃ©rie.  
  - `sources` : Pays du top 10.

**Utilisation dâ€™Elasticsearch :**  
- Recherche dâ€™un titre dans les **top 10 de tous les pays**.  
- GÃ©nÃ©ration de graphiques Ã  partir des **donnÃ©es textuelles**.  

---

### 4ï¸âƒ£ **Dash (Python) : Interface de visualisation**  

Dash est utilisÃ© pour afficher les donnÃ©es sous forme interactive.  

**FonctionnalitÃ©s de Dash :**  
- **Graphiques personnalisables** : Filtrer les films/sÃ©ries selon diffÃ©rentes catÃ©gories (anglais/non-anglais).  
- **Recherche de titres** : VÃ©rifier si un film/sÃ©rie figure dans un top 10 dâ€™un pays.  
- **Affichage dynamique** : Les donnÃ©es sont rÃ©cupÃ©rÃ©es en temps rÃ©el depuis MongoDB et Elasticsearch.  

Lâ€™interface est accessible Ã  lâ€™URL : [http://localhost:8051](http://localhost:8051).  

---

## ğŸ”§ Gestion des Conteneurs avec Docker  

Le projet est entiÃ¨rement conteneurisÃ© avec **Docker Compose**, permettant de dÃ©ployer tous les services en une seule commande.  

## ğŸ“¥ Installation et ExÃ©cution  

### **1ï¸âƒ£ PrÃ©requis**  
Avant de commencer, assurez-vous dâ€™avoir :  
- **Docker** installÃ© 
- **Git** installÃ©  

### **2ï¸âƒ£ Cloner le projet**  
```bash
git clone https://github.com/Liviogit/Projet_DSIA_4201C
cd Projet_DSIA_4201C
```

### **3ï¸âƒ£ Lancer les conteneurs**  
ExÃ©cutez la commande suivante pour **construire et dÃ©marrer tous les services** :  
```bash
docker-compose up --build
```

### **4ï¸âƒ£ AccÃ©der Ã  lâ€™interface**  
Une fois les conteneurs lancÃ©s, ouvrez un navigateur et allez sur :  
[http://localhost:8051](http://localhost:8051)  

---

## ğŸ“‚ Organisation du projet  

```
Projet_DSIA_4201C/
â”œâ”€â”€ dash_app/                   #Conteneur gÃ©nÃ©rant l'interface dash
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ netflix_scraper/            #Contiens les 2 spiders, 2 conteneurs seront crÃ©Ã©s Ã  partir de ce dossier
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Pipfile
â”œâ”€â”€ Pipfile.lock
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml          #Permet la structuration des conteneurs, ainsi que leurs interconnections
â””â”€â”€ requirements.txt

```

---

## ğŸ“Œ Fonctionnement Technique  

### **Scrapy et les Pipelines**  
1. Scrapy se connecte Ã  **https://www.netflix.com/tudum/top10**.  
2. Il extrait les donnÃ©es et les envoie vers la **pipeline MongoDB ou Elasticsearch**.  
3. MongoDB stocke uniquement les **top 10 mondiaux**.  
4. Elasticsearch indexe les **top 10 de tous les pays**.  

### **Docker et lâ€™Orchestration**  
- **`docker-compose up --build`** dÃ©marre tous les conteneurs simultanÃ©ment.  
- **Les dÃ©pendances sont gÃ©rÃ©es automatiquement** (Scrapy attend MongoDB et Elasticsearch avant de s'exÃ©cuter).  
- **Isolation des services** : Chaque composant tourne dans son propre conteneur.  

---

## ğŸ‘¤ Contributeur  
- **Livio Daninthe** (Unique contributeur)  

---

## ğŸ“œ Licence  
Ce projet est open-source.  

---